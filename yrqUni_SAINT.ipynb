{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# config"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch._C import device\ndevice = \"cuda\"\n\nBATCH_SIZE = 450\nTEST_BATCH_SIZE = 450\nTRAIN_FILE = '../input/riiid-test-answer-prediction/train.csv'\nVAL_RATE = 0.01\nMAX_EPOCHS = 5\n\nMAX_SEQ = 100\nEMBED_DIMS = 128\nENC_HEADS = DEC_HEADS = 8\nNUM_ENCODER = NUM_DECODER = 6\nTOTAL_EXE = TOTAL_RESP = 13523\nTOTAL_CAT = 13523","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport datatable as dt\nimport numpy as np\nimport pandas as pd\n \nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nfrom sklearn.model_selection import train_test_split \n\n\nclass Dataset(Dataset):\n  def __init__(self,group,n_skills,max_seq = 100):\n    self.samples = group\n    self.n_skills = n_skills\n    self.max_seq = max_seq\n    self.data = []\n\n    for que,ans,res_time,exe_cat in self.samples:\n        if len(que)>=self.max_seq:\n            self.data.extend([(que[l:l+self.max_seq],ans[l:l+self.max_seq],res_time[l:l+self.max_seq],exe_cat[l:l+self.max_seq])\\\n            for l in range(len(que)) if l%self.max_seq==0])\n        elif len(que)<self.max_seq and len(que)>10:\n            self.data.append((que,ans,res_time,exe_cat))\n        else :\n            continue\n  \n  def __len__(self):\n    return len(self.data)\n  \n  def __getitem__(self,idx):\n    content_ids,answered_correctly,response_time,exe_category = self.data[idx]\n    seq_len = len(content_ids)\n\n    q_ids = np.zeros(self.max_seq,dtype=int)\n    ans = np.zeros(self.max_seq,dtype=int)\n    r_time = np.zeros(self.max_seq,dtype=int)\n    exe_cat = np.zeros(self.max_seq,dtype=int)\n\n    if seq_len>=self.max_seq:\n      q_ids[:] = content_ids[-self.max_seq:]\n      ans[:] = answered_correctly[-self.max_seq:]\n      r_time[:] = response_time[-self.max_seq:]\n      exe_cat[:] = exe_category[-self.max_seq:]\n    else:\n      q_ids[-seq_len:] = content_ids\n      ans[-seq_len:] = answered_correctly\n      r_time[-seq_len:] = response_time\n      exe_cat[-seq_len:] = exe_category\n    \n    decoder_input = np.insert(ans[:-1],0,0)\n    label = ans[:]\n\n    input_ids = np.zeros(self.max_seq,dtype=int)\n    input_ids = q_ids[:].copy()\n\n    input_rtime = np.zeros(self.max_seq,dtype=int)\n    input_rtime = r_time[:].copy()\n\n    input_cat = np.zeros(self.max_seq,dtype=int)\n    input_cat = exe_cat[:].copy()\n\n    input = {\"input_ids\":input_ids,\"input_rtime\":input_rtime.astype(np.int),\"input_cat\":input_cat}\n\n    return input,decoder_input,label \n\ndef get_dataloaders():              \n    dtypes = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16',\n          'answered_correctly':'int8',\"prior_question_elapsed_time\":\"float32\",\"task_container_id\":\"int16\",\n         'content_type_id':'bool'}\n    print(\"loading csv.....\")\n    train_df = dt.fread(TRAIN_FILE, columns=set(dtypes.keys()), max_nrows=1000).to_pandas() # ,max_nrows=1000\n    print(\"shape of dataframe :\",train_df.shape) \n\n    train_df = train_df[train_df.content_type_id==0]\n    train_df.prior_question_elapsed_time /= 1000\n    train_df.prior_question_elapsed_time.fillna(300,inplace=True)\n    train_df.prior_question_elapsed_time.clip(lower=0,upper=300,inplace=True)\n    train_df.prior_question_elapsed_time = train_df.prior_question_elapsed_time.astype(np.int)\n    \n    \n    train_df = train_df.sort_values([\"timestamp\"],ascending=True).reset_index(drop=True)\n    skills = train_df.content_id.unique()\n    n_skills = len(skills)\n    n_cats = len(train_df.task_container_id.unique())+100\n    print(\"no. of skills :\",n_skills)\n    print(\"no. of categories: \", n_cats)\n    print(\"shape after exlusion:\",train_df.shape)\n\n    #grouping based on user_id to get the data supplu\n    print(\"Grouping users...\")\n    group = train_df[[\"user_id\",\"content_id\",\"answered_correctly\",\"prior_question_elapsed_time\",\"task_container_id\"]]\\\n                    .groupby(\"user_id\")\\\n                    .apply(lambda r: (r.content_id.values,r.answered_correctly.values,r.prior_question_elapsed_time.values,r.task_container_id.values))\n    del train_df\n    gc.collect()\n\n    print(\"splitting\")\n    train,val = train_test_split(group,test_size=VAL_RATE) \n    print(\"train size: \",train.shape,\"validation size: \",val.shape)\n    train_dataset = Dataset(train.values,n_skills=n_skills,max_seq = MAX_SEQ)\n    val_dataset = Dataset(val.values,n_skills=n_skills,max_seq = MAX_SEQ)\n    train_loader = DataLoader(train_dataset,\n                          batch_size=BATCH_SIZE,\n                          num_workers=4,\n                          shuffle=True)\n    val_loader = DataLoader(val_dataset,\n                          batch_size=BATCH_SIZE,\n                          num_workers=4,\n                          shuffle=False)\n    del train_dataset,val_dataset,group\n    gc.collect()\n    return train_loader, val_loader","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n.datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n</style>\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# model building"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch import nn\nimport copy\n\ndef ut_mask(seq_len):\n    \"\"\" Upper Triangular Mask\n    \"\"\"\n    return torch.triu(torch.ones(seq_len,seq_len),diagonal=1).to(dtype=torch.bool)\n\ndef lt_mask(seq_len):\n    \"\"\" Upper Triangular Mask\n    \"\"\"\n    return torch.tril(torch.ones(seq_len,seq_len),diagonal=-1).to(dtype=torch.bool)\n\ndef pos_encode(seq_len):\n    \"\"\" position Encoding\n    \"\"\"\n    return torch.arange(seq_len).unsqueeze(0)\n\ndef get_clones(module, N):\n    \"\"\" Cloning nn modules\n    \"\"\"\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\n\n#   MultiHead(Qin,Kin,Vin) = Concat(head1,··· ,headh)WO\nclass FFN(nn.Module):\n  def __init__(self,features):\n    super(FFN,self).__init__()\n    self.layer1 = nn.Linear(features, features)\n    self.layer2 = nn.Linear(features, features)\n    self.relu = nn.ReLU()\n    self.drop = nn.Dropout(0.2)\n    \n  def forward(self, x):\n    out = self.drop(self.relu(self.layer1(x)))\n    out = self.layer2(out)\n    return out\n\nclass MultiHeadWithFFN(nn.Module):\n  def __init__(self,n_heads,n_dims,mask_type=\"ut\",dropout=0.2):\n    super(MultiHeadWithFFN,self).__init__()\n    self.n_dims = n_dims\n    self.mask_type = mask_type\n    self.multihead_attention = nn.MultiheadAttention(embed_dim = n_dims,\n                                                      num_heads = n_heads,\n                                                        dropout = dropout)\n    self.layer_norm1 = nn.LayerNorm(n_dims)\n    self.ffn = FFN(features = n_dims)\n    self.layer_norm2 = nn.LayerNorm(n_dims)\n\n\n  def forward(self,q_input,kv_input):\n    q_input = q_input.permute(1,0,2)\n    kv_input = kv_input.permute(1,0,2)\n    query_norm = self.layer_norm1(q_input)\n    kv_norm = self.layer_norm1(kv_input)\n    if self.mask_type==\"ut\":\n      mask = ut_mask(q_input.size(0))\n    else: \n      mask = lt_mask(q_input.size(0))\n    if device == \"cuda\":\n      mask = mask.cuda()\n    out_atten , weights_attent = self.multihead_attention(query=query_norm,\n                                                key = kv_norm,\n                                                value = kv_norm,\n                                                attn_mask = mask)\n    out_atten +=  query_norm\n    out_atten = out_atten.permute(1,0,2)\n    output_norm = self.layer_norm2(out_atten)\n    output = self.ffn(output_norm)\n    return output + output_norm ","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass SAINT(nn.Module):\n    def __init__(self,n_encoder,n_decoder,enc_heads,dec_heads,n_dims,total_ex,total_cat,total_responses,seq_len):\n        super(SAINT,self).__init__()\n        self.n_encoder = n_encoder\n        self.n_decoder = n_decoder\n        self.enocder = get_clones(EncoderBlock(enc_heads,n_dims,total_ex,total_cat,seq_len),n_encoder)\n        self.decoder = get_clones(DecoderBlock(dec_heads,n_dims,total_responses,seq_len),n_decoder)\n        self.fc = nn.Linear(n_dims,1)\n    \n    def forward(self,in_exercise,in_category,in_response):\n        first_block = True\n        for n in range(self.n_encoder):\n          if n>=1:\n            first_block=False\n          \n          enc = self.enocder[n](in_exercise,in_category,first_block=first_block)\n          in_exercise = enc\n          in_category = enc\n\n        first_block = True\n        for n in range(self.n_decoder):\n          if n>=1:\n            first_block=False\n          dec = self.decoder[n](in_response,encoder_output=in_exercise,first_block=first_block)\n          in_exercise = dec\n          in_response = dec\n          \n        return torch.sigmoid(self.fc(dec))\n\n\n\nclass EncoderBlock(nn.Module):\n  def __init__(self,n_heads,n_dims,total_ex,total_cat,seq_len):\n    super(EncoderBlock,self).__init__()\n    self.seq_len = seq_len\n    self.exercise_embed = nn.Embedding(total_ex,n_dims)\n    self.category_embed = nn.Embedding(total_cat,n_dims)\n    self.position_embed = nn.Embedding(seq_len,n_dims)\n    self.layer_norm = nn.LayerNorm(n_dims)\n    \n    self.multihead = MultiHeadWithFFN(n_heads=n_heads,\n                                            n_dims = n_dims)\n  \n  def forward(self,input_e,category,first_block=True):\n    if first_block:\n      if device == \"cuda\": \n        input_e = input_e.cuda() \n        category = category.cuda() \n        _exe = self.exercise_embed(input_e.long())\n        _cat = self.category_embed(category.long())\n        position_encoded = pos_encode(self.seq_len).cuda()\n        _pos = self.position_embed(position_encoded.long())\n        out = _cat + _exe + _pos\n      else: \n        _exe = self.exercise_embed(input_e.long())\n        _cat = self.category_embed(category.long())\n        position_encoded = pos_encode(self.seq_len)\n        _pos = self.position_embed(position_encoded.long())\n        out = _cat + _exe + _pos\n    else:\n      out = input_e\n    output = self.multihead(q_input=out,kv_input=out)\n    return output\n\n\nclass DecoderBlock(nn.Module):\n    def __init__(self,n_heads,n_dims,total_responses,seq_len):\n      super(DecoderBlock,self).__init__()\n      self.seq_len = seq_len\n      self.response_embed = nn.Embedding(total_responses,n_dims)\n      self.position_embed = nn.Embedding(seq_len,n_dims)\n      self.layer_norm = nn.LayerNorm(n_dims)\n      self.multihead_attention = nn.MultiheadAttention(embed_dim=n_dims,\n                                            num_heads = n_heads,\n                                            dropout = 0.2)\n      self.multihead = MultiHeadWithFFN(n_heads=n_heads,\n                                              n_dims = n_dims)\n\n    def forward(self,input_r,encoder_output,first_block=True):\n      if first_block:\n        _response = self.response_embed(input_r.long())\n        position_encoded = pos_encode(self.seq_len)\n        if device == \"cuda\": \n          position_encoded = position_encoded.cuda()\n        _pos = self.position_embed(position_encoded.long())\n        out = _response + _pos\n      else:\n        out = input_r      \n      out = out.permute(1,0,2)    \n      #assert out_embed.size(0)==n_dims, \"input dimention should be (seq_len,batch_size,dims)\"\n      out_norm = self.layer_norm(out)\n      mask = ut_mask(out_norm.size(0))\n      if device == \"cuda\":\n        mask = mask.cuda()\n      out_atten , weights_attent = self.multihead_attention(query=out_norm,\n                                                  key = out_norm,\n                                                  value = out_norm,\n                                                  attn_mask = mask)\n      out_atten +=  out_norm\n      out_atten = out_atten.permute(1,0,2)\n      output = self.multihead(q_input=out_atten,kv_input=encoder_output)\n      return output\n\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom sklearn.metrics import roc_auc_score\n\nclass Model(pl.LightningModule):\n  def __init__(self,model_args):\n    super().__init__()\n    self.model = SAINT(**model_args)\n    \n  def forward(self,exercise,category,response):#SAINT\n    return self.model(exercise,category,response)#SAINT\n\n\n  def configure_optimizers(self):\n    return torch.optim.Adam(self.parameters(),lr=1e-3)\n  \n  def training_step(self,batch,batch_idx):\n    inputs,decoder_input,target = batch\n    output = self(inputs[\"input_ids\"],inputs[\"input_cat\"],decoder_input)#SAINT\n    target_mask = (decoder_input != 0)\n    output = torch.masked_select(output.squeeze(),target_mask)\n    target = torch.masked_select(target,target_mask)\n    loss = nn.BCEWithLogitsLoss()(output.float(),target.float())\n    return {\"loss\":loss,\"output\":output,\"target\":target}\n \n  def training_epoch_end(self, training_ouput):\n    out = np.concatenate([i[\"output\"].cpu().detach().numpy()\n                          for i in training_ouput]).reshape(-1)\n    labels = np.concatenate([i[\"target\"].cpu().detach().numpy()\n                             for i in training_ouput]).reshape(-1)\n    auc = roc_auc_score(labels, out)\n    self.print(\"train auc\", auc)\n    self.log(\"train_auc\", auc)\n  \n  def validation_step(self,batch,batch_idx):\n    inputs,decoder_input,target = batch\n    output = self(inputs[\"input_ids\"],inputs[\"input_cat\"],decoder_input)#SAINT\n    target_mask = (decoder_input != 0)\n    output = torch.masked_select(output.squeeze(),target_mask)\n    target = torch.masked_select(target,target_mask)\n    loss = nn.BCEWithLogitsLoss()(output.float(),target.float())\n    return {\"val_loss\":loss,\"output\":output,\"target\":target}\n\n  def validation_epoch_end(self, validation_ouput):\n    out = np.concatenate([i[\"output\"].cpu().detach().numpy()\n                          for i in validation_ouput]).reshape(-1)\n    labels = np.concatenate([i[\"target\"].cpu().detach().numpy()\n                             for i in validation_ouput]).reshape(-1)\n    auc = roc_auc_score(labels, out)\n    self.print(\"val auc\", auc)\n    self.log(\"val_auc\", auc)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model train "},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n  train_loader, val_loader = get_dataloaders()\n\n  ARGS = {'n_dims':EMBED_DIMS ,\n          'n_encoder':NUM_ENCODER,\n          'n_decoder':NUM_DECODER,\n          'enc_heads':ENC_HEADS,\n          'dec_heads':DEC_HEADS,\n          'total_ex':TOTAL_EXE,\n          'total_cat':TOTAL_CAT,\n          'total_responses':TOTAL_RESP,\n          'seq_len':MAX_SEQ}\n\n#   checkpoint = ModelCheckpoint(filename=\"{epoch}_model\",\n#                                 verbose=True,\n#                                 save_top_k=1,\n#                                 monitor=\"val_loss\")\n\n  model = Model(model_args=ARGS)\n  \n  trainer = pl.Trainer(progress_bar_refresh_rate=1,\n                       max_epochs=MAX_EPOCHS,\n#                        callbacks=[checkpoint],)\n                       gpus=1)\n  print('Model training start')\n  trainer.fit(model = model,train_dataloader=train_loader,val_dataloaders=val_loader) \n  trainer.save_checkpoint(\"saint_model_\"+str(MAX_EPOCHS)+\"_epochs.pt\")","execution_count":8,"outputs":[{"output_type":"stream","text":"loading csv.....\nshape of dataframe : (1000, 7)\nno. of skills : 871\nno. of categories:  396\nshape after exlusion: (982, 7)\nGrouping users...\nsplitting\ntrain size:  (7,) validation size:  (1,)\n","name":"stdout"},{"output_type":"stream","text":"GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","name":"stderr"},{"output_type":"stream","text":"Model training start\n","name":"stdout"},{"output_type":"stream","text":"\n  | Name  | Type  | Params\n--------------------------------\n0 | model | SAINT | 32.9 M\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.35000000000000003\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"340c0408f21a44f78bc50bfb017c8835"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.45000000000000007\ntrain auc 0.5322274881516588\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.4\ntrain auc 0.5570057115080812\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.4\ntrain auc 0.5469680398590351\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.4\ntrain auc 0.5417790740065622\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"val auc 0.4\ntrain auc 0.5297362984566776\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# model test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ARGS = {'n_dims':EMBED_DIMS ,\n#         'n_encoder':NUM_ENCODER,\n#         'n_decoder':NUM_DECODER,\n#         'enc_heads':ENC_HEADS,\n#         'dec_heads':DEC_HEADS,\n#         'total_ex':TOTAL_EXE,\n#         'total_cat':TOTAL_CAT,\n#         'total_responses':TOTAL_RESP,\n#         'seq_len':MAX_SEQ}\n\n# #   checkpoint = ModelCheckpoint(filename=\"{epoch}_model\",\n# #                                 verbose=True,\n# #                                 save_top_k=1,\n# #                                 monitor=\"val_loss\")\n\n# model = Model(model=\"saint\",model_args=ARGS)\n# model = model.load_from_checkpoint('../input/yrquni-riiid/lightning_logs/version_0/checkpoints/epoch=4.ckpt',model_args=ARGS)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.eval().to(device)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import gc\n# import datatable as dt\n# import numpy as np\n# import pandas as pd\n \n# from torch.utils.data import Dataset, DataLoader\n# import gc\n# from sklearn.model_selection import train_test_split \n\n\n# class TestDataset(Dataset):\n#   def __init__(self,group,n_skills,max_seq = 100):\n#     self.samples = group\n#     self.n_skills = n_skills\n#     self.max_seq = max_seq\n#     self.data = []\n\n#     for user_id,buf in self.samples:\n#         que,ans,res_time,exe_cat,row_id = buf\n#         if len(que)>=self.max_seq:\n#             self.data.extend([(user_id,que[-self.max_seq:],ans[-self.max_seq:],res_time[-self.max_seq:],exe_cat[-self.max_seq:],row_id[-self.max_seq:])])\n#         elif len(que)<self.max_seq and len(que)>10:\n#             self.data.append((user_id,que,ans,res_time,exe_cat,row_id))\n#         else :\n#             self.data.append((user_id,que,ans,res_time,exe_cat,row_id))\n  \n#   def __len__(self):\n#     return len(self.data)\n  \n#   def __getitem__(self,idx):\n#     user_id,content_ids,answered_correctly,response_time,exe_category,row_id = self.data[idx]\n#     seq_len = len(content_ids)\n\n#     q_ids = np.zeros(self.max_seq,dtype=int)\n#     ans = np.zeros(self.max_seq,dtype=int)\n#     r_time = np.zeros(self.max_seq,dtype=int)\n#     exe_cat = np.zeros(self.max_seq,dtype=int)\n#     row_id_  = np.zeros(self.max_seq,dtype=int)\n    \n    \n#     if seq_len>=self.max_seq:\n#       q_ids[:] = content_ids[-self.max_seq:]\n#       ans[:] = answered_correctly[-self.max_seq:]\n#       r_time[:] = response_time[-self.max_seq:]\n#       exe_cat[:] = exe_category[-self.max_seq:]\n#       row_id_[:] = row_id[-self.max_seq:]\n#     else:\n#       q_ids[-seq_len:] = content_ids\n#       ans[-seq_len:] = answered_correctly\n#       r_time[-seq_len:] = response_time\n#       exe_cat[-seq_len:] = exe_category\n#       row_id_[-seq_len:] = row_id\n    \n#     decoder_input = np.insert(ans[:-1],0,0)\n#     label = ans[:]\n\n#     input_ids = np.zeros(self.max_seq,dtype=int)\n#     input_ids = q_ids[:].copy()\n\n#     input_rtime = np.zeros(self.max_seq,dtype=int)\n#     input_rtime = r_time[:].copy()\n\n#     input_cat = np.zeros(self.max_seq,dtype=int)\n#     input_cat = exe_cat[:].copy()\n    \n#     inputs = {\"input_ids\":input_ids,\"input_rtime\":input_rtime.astype(np.int),\"input_cat\":input_cat}\n\n#     row_id_test = np.zeros(self.max_seq,dtype=int)\n#     row_id_test = row_id_[:].copy()\n    \n#     user_id_test = np.zeros(self.max_seq,dtype=int)\n#     user_id_test = np.repeat(user_id, self.max_seq, axis=0)\n\n#     return inputs,decoder_input,label,row_id_test,user_id_test\n\n# def get_Test_dataloaders(train_df,test_df,test_user_id):    \n    \n#     dtypes = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16',\n#           'answered_correctly':'int8',\"prior_question_elapsed_time\":\"float32\",\"task_container_id\":\"int16\",\n#          'content_type_id':'bool','row_id':'int'}\n#     train_df = train_df.loc[train_df.user_id.isin(test_user_id)]\n#     test_df = train_df.append(test_df.loc[test_df.user_id.isin(test_user_id)],dtypes.keys())\n\n#     test_df = test_df[test_df.content_type_id==0]\n#     test_df.prior_question_elapsed_time /=1000\n#     test_df.prior_question_elapsed_time.fillna(300,inplace=True)\n#     test_df.prior_question_elapsed_time.clip(lower=0,upper=300,inplace=True)\n#     test_df.prior_question_elapsed_time = test_df.prior_question_elapsed_time.astype(np.int)\n      \n#     test_df = test_df.sort_values([\"timestamp\"],ascending=True).reset_index(drop=True)\n#     skills = test_df.content_id.unique()\n#     n_skills = len(skills)\n#     n_cats = len(test_df.task_container_id.unique())+100\n\n#     #grouping based on user_id to get the data supplu\n#     group = test_df[[\"user_id\",\"content_id\",\"answered_correctly\",\"prior_question_elapsed_time\",\"task_container_id\",'row_id']]\\\n#                     .groupby(\"user_id\")\\\n#                     .apply(lambda r: (r.content_id.values,r.answered_correctly.values,r.prior_question_elapsed_time.values,r.task_container_id.values,r.row_id.values)).reset_index()\n#     del train_df,test_df\n#     gc.collect()\n#     test_dataset = TestDataset(group.values,n_skills=n_skills,max_seq = MAX_SEQ)\n#     test_loader = DataLoader(test_dataset,\n#                           batch_size=TEST_BATCH_SIZE,\n#                           num_workers=4,\n#                           shuffle=False)\n#     del test_dataset, group\n#     gc.collect()\n#     return test_loader","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# strat test loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import riiideducation\n\n# env = riiideducation.make_env()\n# iter_test = env.iter_test()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import psutil\n# prev_test_df = None\n# test_df_all = None\n\n# dtypes = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16',\n#           'answered_correctly':'int8',\"prior_question_elapsed_time\":\"float32\",\"task_container_id\":\"int16\",\n#          'content_type_id':'bool','row_id':'int'}\n# print(\"loading csv.....\")\n# train_df = dt.fread(TRAIN_FILE, columns=set(dtypes.keys()), ).to_pandas()#,max_nrows=1000","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BUF = pd.DataFrame()\n\n# for (test_df, sample_prediction_df) in iter_test:\n#     print('test_df user_id nums: ',len(test_df.copy().user_id.values))\n#     test_user_id = test_df.copy().user_id.unique()\n#     if (prev_test_df is not None) & (psutil.virtual_memory().percent < 90):\n#         test_df['answered_correctly'] = -1\n#         prev_test_df.loc[prev_test_df.answered_correctly==-1,'answered_correctly'] = eval(test_df['prior_group_answers_correct'].copy().iloc[0])\n#         prev_test_df = prev_test_df.append(test_df[dtypes.keys()].copy()).copy()\n#         test_df_all = prev_test_df.copy()\n#         test_df_all['answered_correctly'].replace(-1,0,inplace=True)\n   \n#     else:\n#         test_df['answered_correctly'] = -1\n#         prev_test_df = test_df.copy()\n#         test_df_all = test_df.copy()\n#         test_df_all['answered_correctly'].replace(-1,0,inplace=True)\n        \n#     test_df_all = test_df_all[test_df_all.content_type_id == False]\n#     test_loader = get_Test_dataloaders(train_df,test_df_all,test_user_id)\n   \n#     ans = []\n#     user_id_buf = []\n#     row_id_test_buf = []\n#     for inputs,decoder_input,label,row_id_test,user_id_test in test_loader:\n#         outs = model(inputs[\"input_ids\"].flatten().view(-1,MAX_SEQ).to(device),\n#                      inputs[\"input_cat\"].flatten().view(-1,MAX_SEQ).to(device),\n#                      decoder_input.flatten().view(-1,MAX_SEQ).to(device))\n#         ans.extend(torch.sigmoid(outs).view(-1).data.cpu().numpy())\n#         user_id_buf.extend(user_id_test.view(-1).data.cpu().numpy())\n#         row_id_test_buf.extend(row_id_test.view(-1).data.cpu().numpy())\n       \n#     ans_df_buf = pd.DataFrame({'user_id':user_id_buf,'row_id':row_id_test_buf,'answered_correctly':ans})\n    \n#     test_df = pd.merge(test_df.drop(columns=['answered_correctly']),ans_df_buf,on=['user_id','row_id'],how='left')\n#     env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n    \n#     BUF = BUF.append(test_df)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# preview the submit DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"# BUF.loc[BUF['content_type_id'] == 0, ['row_id', 'answered_correctly']].answered_correctly.isnull().any()","execution_count":15,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}